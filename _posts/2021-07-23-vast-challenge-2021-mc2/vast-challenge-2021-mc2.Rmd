---
title: "VAST Challenge 2021 MC2"
description: |
  To visualize and analyze movement and tracking data
author:
  - name: LIU Yangguang
    url: https://www.linkedin.com/in/ygliu/
    affiliation: School of Computing and Information Systems, Singapore Management
date: 07-23-2021
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_depth: 2
categories:
  - R
  - Visualization
preview: data/MC2-tourist.jpg
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)
```


## Background

This study is based on the [Mini-Challenge 2](https://vast-challenge.github.io/2021/MC2.html) of the [VAST Challenge 2021](https://vast-challenge.github.io/2021/). In a fiction scenario, there is a natural gas company named "GASTech" operating in the island country if Kronos. The GASTech didn't do well in environment stewardship. And after an company IPO celebration in January 2014, several employees of GASTech went missing. An environment organization is suspected in the disappearance.

Many of the Abila, Kronos-based employees of GAStech have company cars which are approved for both personal and business use. And the others who don't have company cars can check and use company trucks for business use. The GPS tracking data of these company vehicles is available for the two weeks prior the disappearance.

And the company also provides a loyalty card to employees to give them discounts in the local businesses. And their credit card purchases and loyalty cards usage data are provided. But these data does not have persona information beyond purchases.

### Requirement

Use visual analytics to identify which GASTech employees made which purchases and identify suspicious patterns of behavior. Besides, the study must cope with uncertainties that result from missing, conflicting, and imperfect data to make recommendations for further investigation.

### Questions

1. Using just the credit and loyalty card data, identify the most popular locations, and when they are popular. What anomalies do you see? What corrections would you recommend to correct these anomalies? Please limit your answer to 8 images and 300 words.

2. Add the vehicle data to your analysis of the credit and loyalty card data. How does your assessment of the anomalies in question 1 change based on this new data? What discrepancies between vehicle, credit, and loyalty card data do you find? Please limit your answer to 8 images and 500 words.

3. Can you infer the owners of each credit card and loyalty card? What is your evidence? Where are there uncertainties in your method? Where are there uncertainties in the data? Please limit your answer to 8 images and 500 words.

4. Given the data sources provided, identify potential informal or unofficial relationships among GASTech personnel. Provide evidence for these relationships. Please limit your response to 8 images and 500 words.

5. Do you see evidence of suspicious activity? Identify 1- 10 locations where you believe the suspicious activity is occurring, and why Please limit your response to 10 images and 500 words.

### Literature review

The VAST Challenge 2014 has the same scenario with slightly different dataset and questions. The submission repository can be found [here](http://visualdata.wustl.edu/varepository/VAST%20Challenge%202014/challenges/MC2%20-%20Patterns%20of%20Life%20Analysis/).

Various analytic tools were used among the submissions, like JMP, D3 and custom tools. The heatmap and time histograms were useful to represent the numerical value under the combination of one  categorical variable and one discrete/categorical variable, such as the usage frequency under different locations and days. Besides, movement line graph with the map background  can help to identify and check suspicious activities.

However, almost all graphs were static and readers would find it difficult to explore other parts in graphs which were not specially mentioned by authors. Since the study is displayed on html page, the interactive graphs will be possible. For example, the tooltip function can make every data point to have detailed information without checking the axis or drawing additional graphs. The zoom-in and onclick functions allow readers to check the whole complex graph with too many lines/objects and focus on one part only.  



## Data Preparation

Extracting, wrangling and preparing the input data required to perform the analysis. The focus should be on exploring appropriate **tidyverse** methods

### QGIS



## Visualization and Insights

### Q1:
以地点为单位
按照day的freq和price的热力图，分别看两个数据产生的热力图是否有不一致+两幅图联动选择；
按照24小时的热力图，单幅
hour*day的freq + 加上它是星期几的tooltip？
交互的可以选择人和day的24小时的热力图？
多个波动的折线图上下重叠？
异常指数据异常，而不是可疑活动

```{r}
library(tidyverse)
library(ggplot2)
library(lubridate)
library(dplyr)
library(plotly)
```


```{r}
loyalty <- read_csv("data/loyalty_data.csv", locale=locale(encoding ="windows-1252"))
cc <- read_csv("data/cc_data.csv", locale=locale(encoding ="windows-1252"))
```

```{r}
# convert str into date/time
loyalty$timestamp <- as.Date(loyalty$timestamp, "%m/%d/%Y")
loyalty$day <- mday(loyalty$timestamp)
cc$datetime <- strptime(cc$timestamp, "%m/%d/%Y %H:%M")
cc$date <- as.Date(cc$timestamp, "%m/%d/%Y %H:%M")
cc$day <- mday(cc$date)
cc$hour <- hour(cc$datetime)
```



```{r}
cc_freq_day <- as.data.frame(xtabs(~location+day, data = cc)) # 二维列联表
loyalty_freq_day <- as.data.frame(xtabs(~location+day, data = loyalty)) # 二维列联表

freq_day_join <- full_join(cc_freq_day,loyalty_freq_day,by= c("location","day"))
names(freq_day_join) <- c("location","day","CC_Freq","Loyalty_Freq")
freq_day_join$day <- as.integer(freq_day_join$day)
dt_freq_day <- highlight(freq_day_join)
p1 <- ggplot(dt_freq_day,aes(x=day,y=location))+
  geom_tile(aes(fill=CC_Freq))+
  scale_fill_gradient(low = "#deeff7", high = "#0D2330")+
  theme(panel.background = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank())

p2 <- ggplot(dt_freq_day,aes(x=day,y=location))+
  geom_tile(aes(fill=Loyalty_Freq))+
  scale_fill_gradient(low = "#deeff7", high = "#0D2330")+
  theme(panel.background = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank())

plotly::subplot(ggplotly(p1),
                ggplotly(p2),
                shareY = TRUE) %>% 
  layout(annotations = list(x = 0.02 , y = 1.06, text = "Usage Frequency of Credit (left) and Loyalty (right) Card", showarrow = F, xref='paper', yref='paper'))
```

```{r}
cc_price_matrix <- tapply(cc$price,cc[,c("location","day")],sum)
cc_price <- reshape2::melt(cc_price_matrix)

loyalty_price_matrix <- tapply(loyalty$price,loyalty[,c("location","day")],sum)
loyalty_price <- reshape2::melt(loyalty_price_matrix)

price_day_join <- full_join(cc_price,loyalty_price,by= c("location","day"))
names(price_day_join) <- c("location","day","Price.","Price")
# price_day_join$Price.[is.na(price_day_join$Price.)] <- 0
# price_day_join$Price[is.na(price_day_join$Price)] <- 0
p1_price <- ggplot(price_day_join,aes(x=day,y=location))+
  geom_tile(aes(fill=Price.))+
  scale_fill_gradient(low = "#deeff7", high = "#0D2330")+
  theme(panel.background = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank())
p2_price <- ggplot(price_day_join,aes(x=day,y=location))+
  geom_tile(aes(fill=Price))+
  scale_fill_gradient(low = "#deeff7", high = "#0D2330")+
  theme(panel.background = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank())

plotly::subplot(ggplotly(p1_price),
        ggplotly(p2_price),
        shareY = TRUE)

```

#### most popular locations:...

Now, let's divide the units from days into hours:

```{r, layout="l-screen", fig.height=10}
cc_freq_day_hour <- as.data.frame(xtabs(~location++day+hour, data = cc))
cc_freq_day_hour$hour <- as.integer(cc_freq_day_hour$hour)
p3 <- ggplot(cc_freq_day_hour,aes(x=hour,y=location))+
  geom_tile(aes(fill=Freq),color="white")+
  scale_fill_gradient(low = "#EFF7FB", high = "#0D2330")+
  theme(panel.background = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        plot.title = element_text(hjust=0.5))+
  facet_wrap(~ day, ncol = 7)+
  labs(title = "CC Frequency by hour of the day") 
ggplotly(p3)
```



#### Anomalies:


### Q2：
画地图时，参考清华的Q3的流程
需要考虑的包，包括mapview，S8有写


### Q3:
S9里的Bipartite：匹配信用卡和会员数据？
美化可以参考-Parallel Sets of https://cheriewpq.shinyapps.io/isss608_group02/
定义所有car stop大于1分钟的作为一次stop，找出所有stop的gps定位。得到停车的开始结束时间+stop的定位
和cc的数据全连接，然后统计匹配航叔的频次？画出Bipartite？

### Q4:
鉴别potential informal or unofficial relationships among GASTech personnel.

### Q5:
suspicious activity: Identify 1- 10 locations where you believe the suspicious activity is occurring, and why Please limit your response to 10 images and 500 words.

卡车，用于非商业活动的也算可疑活动

day*hour的图片

## Conclusion


